{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Libraries\nimport os\nimport sys\nsys.path=['../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master',]+sys.path\nimport pandas as pd\nimport numpy as np\nfrom sklearn import metrics\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nfrom efficientnet_pytorch import model as enet\nimport random\nfrom torchvision import datasets, transforms, models\nfrom sklearn.model_selection import StratifiedKFold\nimport codecs\npytorch_models = models","metadata":{"execution":{"iopub.status.busy":"2022-01-17T14:02:41.814224Z","iopub.execute_input":"2022-01-17T14:02:41.815084Z","iopub.status.idle":"2022-01-17T14:02:43.936560Z","shell.execute_reply.started":"2022-01-17T14:02:41.814972Z","shell.execute_reply":"2022-01-17T14:02:43.935782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed = 0):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    random_state = np.random.RandomState(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    return random_state\n\nrandom_state = set_seed(2021)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-17T14:02:43.938867Z","iopub.execute_input":"2022-01-17T14:02:43.939387Z","iopub.status.idle":"2022-01-17T14:02:43.949356Z","shell.execute_reply.started":"2022-01-17T14:02:43.939347Z","shell.execute_reply":"2022-01-17T14:02:43.948563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"GPU is available\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU not available, CPU used\")","metadata":{"execution":{"iopub.status.busy":"2022-01-17T14:02:43.951538Z","iopub.execute_input":"2022-01-17T14:02:43.951927Z","iopub.status.idle":"2022-01-17T14:02:44.018921Z","shell.execute_reply.started":"2022-01-17T14:02:43.951891Z","shell.execute_reply":"2022-01-17T14:02:44.018017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ClassificationDataset:\n    \n    def __init__(self, image_paths, targets): \n        self.image_paths = image_paths\n        self.targets = targets\n\n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):      \n        image = np.load(self.image_paths[item]).astype(float)\n\n        targets = self.targets[item]\n                \n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"targets\": torch.tensor(targets, dtype=torch.long),\n        }","metadata":{"execution":{"iopub.status.busy":"2022-01-17T14:02:44.020789Z","iopub.execute_input":"2022-01-17T14:02:44.021387Z","iopub.status.idle":"2022-01-17T14:02:44.029490Z","shell.execute_reply.started":"2022-01-17T14:02:44.021346Z","shell.execute_reply":"2022-01-17T14:02:44.028701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train=pd.read_csv('../input/seti-breakthrough-listen/train_labels.csv')\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-17T14:02:44.030724Z","iopub.execute_input":"2022-01-17T14:02:44.031075Z","iopub.status.idle":"2022-01-17T14:02:44.104828Z","shell.execute_reply.started":"2022-01-17T14:02:44.031039Z","shell.execute_reply":"2022-01-17T14:02:44.104070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['img_path']=df_train['id'].apply(lambda x:f'../input/seti-breakthrough-listen/train/{x[0]}/{x}.npy')\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-17T14:02:44.105993Z","iopub.execute_input":"2022-01-17T14:02:44.106319Z","iopub.status.idle":"2022-01-17T14:02:44.145564Z","shell.execute_reply.started":"2022-01-17T14:02:44.106285Z","shell.execute_reply":"2022-01-17T14:02:44.144659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class enetv2(nn.Module):\n    def __init__(self, backbone, out_dim):\n        super(enetv2, self).__init__()\n        self.enet = enet.EfficientNet.from_name(backbone)\n        self.enet.load_state_dict(torch.load(pretrained_model[backbone]))\n        self.myfc = nn.Linear(self.enet._fc.in_features, out_dim)\n        self.enet._fc = nn.Identity()\n        self.conv1 = nn.Conv2d(6, 3, kernel_size=3, stride=1, padding=3, bias=False)\n\n    def extract(self, x):\n        return self.enet(x)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.extract(x)\n        x = self.myfc(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-01-17T14:02:44.146980Z","iopub.execute_input":"2022-01-17T14:02:44.147318Z","iopub.status.idle":"2022-01-17T14:02:44.154600Z","shell.execute_reply.started":"2022-01-17T14:02:44.147282Z","shell.execute_reply":"2022-01-17T14:02:44.153509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import OrderedDict\ndef train(data_loader, model, optimizer, device):\n    \n    model.train()\n    running_loss = 0.0\n    i = 0\n    \n    for data in tqdm(data_loader, position=0, leave=True, desc='Training'):\n        i = i + 1\n        inputs = data[\"image\"]\n        targets = data['targets']\n        \n        inputs = inputs.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        outputs = outputs.squeeze()\n        loss = nn.BCEWithLogitsLoss()\n        output_loss = loss(outputs, targets)\n        output_loss.backward()\n        optimizer.step()\n        running_loss += output_loss.item()\n        if i % 100 == 99:    # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (1 + 1, i + 1, running_loss / 2000))\n            running_loss = 0.0\n        \n        \ndef evaluate(data_loader, model, device):\n    model.eval()\n    \n    final_targets = []\n    final_outputs = []\n    \n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            inputs = data[\"image\"]\n            targets = data[\"targets\"]\n            inputs = inputs.to(device, dtype=torch.float)\n            targets = targets.to(device, dtype=torch.float)\n            \n            output = model(inputs)\n            \n            targets = targets.detach().cpu().numpy().tolist()\n            output = output.detach().cpu().numpy().tolist()\n            \n            final_targets.extend(targets)\n            final_outputs.extend(output)\n            \n    return final_outputs, final_targets\ntorch.cuda.empty_cache()\n\nbaseline_name = 'efficientnet-b1'\npretrained_model = {\n    baseline_name: '../input/resnet18'\n}\nmodels = []\ndevice = \"cuda\"\nepochs = 20\nBatch_Size = 32\nX = df_train.img_path.values\nY = df_train.target.values\nskf = StratifiedKFold(n_splits=5)\nfold = 0\n\n\nfor train_index, test_index in skf.split(X, Y):\n    \n    model = pytorch_models.resnet18()\n    model.load_state_dict(torch.load(\"../input/resnet18/resnet18.pth\"))\n    \n\n    old_conv_weight = model.conv1.weight.data #get old weights\n    new_conv = nn.Conv2d(6, 64, kernel_size=7, stride=1, padding=3, bias=False) #create new conv layer\n    nn.init.xavier_normal_(new_conv.weight) #xavier init\n    new_conv.weight.data[:,:3].copy_(old_conv_weight) #copy old weights into first 3 channels\n    new_conv.to(device)\n    model.conv1 = new_conv #replace old conv with the new one\n    \n    layers = nn.Sequential(OrderedDict([\n      ('fc1', nn.Linear(512, 256)),\n      ('activation1', nn.ReLU()),\n      ('dropout1', nn.Dropout()),\n      ('fc2', nn.Linear(256, 128)),\n      ('activation2', nn.ReLU()),\n      ('dropout2', nn.Dropout()),\n       ('fc3', nn.Linear(128, 1))])).to(device)\n\n    model.fc = layers\n    #model.fc = nn.Linear(512,2)\n    model.to(device)\n    \n    train_images, valid_images = X[train_index], X[test_index]\n    train_targets, valid_targets = Y[train_index], Y[test_index]\n    train_dataset = ClassificationDataset(image_paths=train_images, targets=train_targets)\n    valid_dataset = ClassificationDataset(image_paths=valid_images, targets=valid_targets)\n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=Batch_Size,shuffle=True, num_workers=4)\n    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=Batch_Size,shuffle=False, num_workers=4)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n    \n\n    best_roc_auc = 0\n    for epoch in range(epochs):\n        if epoch == 3:\n            for param_group in optimizer.param_groups:\n                param_group[\"lr\"] = 1e-4\n        if epoch == 4:\n            for param_group in optimizer.param_groups:\n                param_group[\"lr\"] = 1e-6\n        \n        train(train_loader, model, optimizer, device=device)\n        predictions, valid_targets = evaluate(valid_loader, model, device=device)\n        roc_auc = metrics.roc_auc_score(valid_targets, predictions)\n        print(f\"Epoch={epoch}, Valid ROC AUC={roc_auc}\")\n        \n        with codecs.open('log.log', 'a') as up:\n            up.write(f\"Fold={fold}, Epoch={epoch}, Valid ROC AUC={roc_auc}/{best_roc_auc}\\n\")\n\n        if roc_auc > best_roc_auc:        \n            torch.save(model.state_dict(), baseline_name + '-' + str(fold) + '-' + str(epoch) + '.pt')\n            best_roc_auc = roc_auc\n            \n    torch.save(model.state_dict(),baseline_name + '-' + str(fold) + '.pt')\n    models.append(model)\n    fold += 1\n    break\n    #todo: reduce target dimension to 32","metadata":{"execution":{"iopub.status.busy":"2022-01-17T14:02:44.156284Z","iopub.execute_input":"2022-01-17T14:02:44.156678Z","iopub.status.idle":"2022-01-17T14:31:37.753737Z","shell.execute_reply.started":"2022-01-17T14:02:44.156639Z","shell.execute_reply":"2022-01-17T14:31:37.751705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(kurva)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T14:32:32.727999Z","iopub.execute_input":"2022-01-17T14:32:32.728345Z","iopub.status.idle":"2022-01-17T14:32:32.733630Z","shell.execute_reply.started":"2022-01-17T14:32:32.728311Z","shell.execute_reply":"2022-01-17T14:32:32.732623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T14:31:37.761710Z","iopub.execute_input":"2022-01-17T14:31:37.762042Z","iopub.status.idle":"2022-01-17T14:31:37.772180Z","shell.execute_reply.started":"2022-01-17T14:31:37.762008Z","shell.execute_reply":"2022-01-17T14:31:37.770991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(data_loader, model, device):\n    model.eval()\n    \n    final_targets = []\n    final_outputs = []\n    \n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            inputs = data[\"image\"]\n            targets = data[\"targets\"]\n            inputs = inputs.to(device, dtype=torch.float)\n            targets = targets.to(device, dtype=torch.long)\n            \n            output = model(inputs)\n            print(targets, output)\n            targets = targets.detach().cpu().numpy().tolist()\n            output = output.detach().cpu().numpy().tolist()\n            \n            final_targets.extend(targets)\n            final_outputs.extend(output)\n            \n    return final_outputs, final_targets\n\npredictions, valid_targets = evaluate(valid_loader, model, device=device)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T14:31:37.774739Z","iopub.execute_input":"2022-01-17T14:31:37.775385Z","iopub.status.idle":"2022-01-17T14:32:22.410721Z","shell.execute_reply.started":"2022-01-17T14:31:37.775344Z","shell.execute_reply":"2022-01-17T14:32:22.408425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission=pd.read_csv('../input/seti-breakthrough-listen/sample_submission.csv')\nsubmission['img_path']=submission['id'].apply(lambda x:f'../input/seti-breakthrough-listen/test/{x[0]}/{x}.npy')","metadata":{"execution":{"iopub.status.busy":"2022-01-17T14:32:22.412096Z","iopub.status.idle":"2022-01-17T14:32:22.412897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset=ClassificationDataset(image_paths=submission.img_path.values, targets=submission.target.values)\ntest_loader=torch.utils.data.DataLoader(test_dataset, batch_size=16,shuffle=False,num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T14:32:22.414194Z","iopub.status.idle":"2022-01-17T14:32:22.414991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sig=torch.nn.Sigmoid()\nouts=[]\nfor model in models:\n    predictions,valid_targets=evaluate(test_loader, model, device=device)\n    predictions=np.array(predictions)[:,0]\n    out=sig(torch.from_numpy(predictions))\n    out=out.detach().numpy()\n    outs.append(out)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-17T14:32:22.416204Z","iopub.status.idle":"2022-01-17T14:32:22.417000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred=np.mean(np.array(outs),axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T14:32:22.418234Z","iopub.status.idle":"2022-01-17T14:32:22.419030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.target=pred\nsubmission.drop(['img_path'],axis=1,inplace=True)\nsubmission.to_csv('submission.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-17T14:32:22.420233Z","iopub.status.idle":"2022-01-17T14:32:22.421031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head(30)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T14:32:22.422250Z","iopub.status.idle":"2022-01-17T14:32:22.423022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sig=torch.nn.Sigmoid()\n\n\nfor model in models:\n    predictions,valid_targets=evaluate(valid_loader, model, device=device)\n    predictions=np.array(predictions)[:,0]\n    out=sig(torch.from_numpy(predictions))\n    out=out.detach().numpy()\n    outs.append(out)\nprint(outs)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-17T14:32:22.424252Z","iopub.status.idle":"2022-01-17T14:32:22.425036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred=np.mean(np.array(outs),axis=0)\nhits = 0\nmisses = 0\nfor i in range(len(predictions)):\n    if pred[i] >=0.5 and valid_targets[i] == 1.0:\n        hits+=1\n    elif pred[i] <0.5 and valid_targets[i] == 0.0:\n        hits+=1\n    else:\n        misses+=1\nprint(hits/len(predictions))\nprint(len(predictions))\nprint(hits+misses)\nprint(hits)\nprint(outs)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T14:32:22.426259Z","iopub.status.idle":"2022-01-17T14:32:22.427053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for data in testloader:\n        images, labels = data\n        images, labels = data[0].to(device), data[1].to(device)\n        images, labels = inputs.to(device), labels.to(device)\n        # calculate outputs by running images through the network\n        outputs = net(images)\n        # the class with the highest energy is what we choose as prediction\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()","metadata":{"execution":{"iopub.status.busy":"2022-01-17T14:32:22.428254Z","iopub.status.idle":"2022-01-17T14:32:22.429087Z"},"trusted":true},"execution_count":null,"outputs":[]}]}