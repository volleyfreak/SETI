{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":" Like probably many of you, I was *very* surprised when I saw the final results this morning. As the discussion [here](https://www.kaggle.com/c/seti-breakthrough-listen/discussion/266385) has shown, the key to the large distance between the winning solution and #2 was what the winning team called \"magic #2\". This method allowed them to remove background noise completely for at least some samples. Achieving this would be a kind of Holy Grail for experimental physics, so I really wanted to understand this method. At first, I couldn't wrap my head aroungd their explanation, so I started to reimplement it on my own.\n \nDISCLAIMER: even though I think that in the end it is some kind of leak, the winning team's solution is absolutely brilliant. I would have never figured this out on my own. And of course, I'm not 100% sure that this is all there is to \"magic #2\". This is just my attempt at an explanation.\n \nBy now, the following is clear to me:\n\nThe key is that the true measured background signals used in this competition are far wider in the frequency range than 256 bins. Therefore, the organizers cut the data up into bands of 256 bins each and used these as samples. However, for reasons unclear to me they user *severely* overlapping samples. Therefore, for most samples in the datasets, you can -partially- find that data again in another sample. If one of them contains a needle, you can perfectly remove any noise.\nThe only remaining problem is the fact that each image in a sample is independently normalized to mean=0, std=1. This needs to be reversed.\n\nI will demonstrate this for one sample:","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-19T20:44:20.193154Z","iopub.execute_input":"2021-08-19T20:44:20.193582Z","iopub.status.idle":"2021-08-19T20:44:20.198202Z","shell.execute_reply.started":"2021-08-19T20:44:20.193545Z","shell.execute_reply":"2021-08-19T20:44:20.19729Z"}}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:01:07.80186Z","iopub.execute_input":"2022-02-28T10:01:07.802297Z","iopub.status.idle":"2022-02-28T10:01:07.814081Z","shell.execute_reply.started":"2022-02-28T10:01:07.80221Z","shell.execute_reply":"2022-02-28T10:01:07.813174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INPUT_DIR = \"../input/seti-breakthrough-listen\"\ndf_train = pd.read_csv(os.path.join(INPUT_DIR, \"train_labels.csv\"))\ndf_subm = pd.read_csv(os.path.join(INPUT_DIR, \"sample_submission.csv\"))\ndf_train_pos = df_train[df_train.target == 1]\ndf_train_neg = df_train[df_train.target == 0]","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:01:07.820691Z","iopub.execute_input":"2022-02-28T10:01:07.821407Z","iopub.status.idle":"2022-02-28T10:01:08.084416Z","shell.execute_reply.started":"2022-02-28T10:01:07.821364Z","shell.execute_reply":"2022-02-28T10:01:08.082989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Helper functions for loading and displaying samples:","metadata":{}},{"cell_type":"code","source":"def load_example(idx):\n    try:\n        x = np.load(os.path.join(INPUT_DIR, \"train\", idx[0], idx + \".npy\"))\n    except:\n        x = np.load(os.path.join(INPUT_DIR, \"test\",  idx[0], idx + \".npy\"))\n    return np.take(x.astype(np.float32), [0,2,4], 0)\n\n\ndef show_example(x, p=0):\n    x = x.reshape(-1, 256)\n    x = np.clip(x, np.percentile(x, p), np.percentile(x, 100-p)) # clip for better contrast\n    \n    fig, ax = plt.subplots()\n    fig.set_size_inches(9, 9)\n    ax.set_xticks(np.arange(1,3)*273)\n    ax.set_yticks([])\n    ax.grid(True)\n    ax.imshow(x.T, aspect=\"auto\", cmap=\"Greys\")","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:01:08.086841Z","iopub.execute_input":"2022-02-28T10:01:08.08735Z","iopub.status.idle":"2022-02-28T10:01:08.098046Z","shell.execute_reply.started":"2022-02-28T10:01:08.087299Z","shell.execute_reply":"2022-02-28T10:01:08.096777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's take a look at one sample which contains a needle with a very low SNR, definitely not visible by eye, the 5th positive sample in train. Time is the horizontal direction, frequency vertical:","metadata":{}},{"cell_type":"code","source":"idx = df_train_pos.id.iloc[5]\nprint(idx)\nx0 = load_example(idx)\nshow_example(x0, 1)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:01:08.09978Z","iopub.execute_input":"2022-02-28T10:01:08.100281Z","iopub.status.idle":"2022-02-28T10:01:08.514797Z","shell.execute_reply.started":"2022-02-28T10:01:08.100234Z","shell.execute_reply":"2022-02-28T10:01:08.513099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I'm doing the \"renormalization\" similar to but probably different from the winning team. I start with one normalized reference column and check if this column is found somewhere else in the data:","metadata":{}},{"cell_type":"code","source":"def column_norm(x):\n    ''' normalizes each column of 273 pixels in each of the 6 images in sample x separately \n    to mean==0 and L2 norm==1 '''\n    \n    xn  = x - np.mean(x, axis=1, keepdims=True) # remove mean\n    xn /= np.sqrt(np.sum(xn to **2, axis=1, keepdims=True)) # normalize\n    return xn  \ndef find_similar_column_old(col0, xn1):\n    ''' calculates cosine similarity between the normalized reference column col0 and all columns\n        in the column-normalized sample xn1 '''\n    \n    return np.array([ [ np.dot(col0, col1) for col1 in img.T ] for img in xn1 ])\n\ndef find_similar_column(image0, image1):\n    ''' calculates shift of image '''\n    middle_column = int(len(image1)/2)\n    sums = [0] * len(image1[middle_column])\n    #for (z, col1) in enumerate(image1):\n    col1 = image1[middle_column]\n    col0 = image0[middle_column]\n    for (i, data) in enumerate(col1):\n        col1_rolled = np.roll(col1, i, axis=0)\n        result = np.sum(np.square(col0 - col1_rolled))\n        sums[i] += result\n            #bestMatch.append((i, result))  \n    return (sums.index(min(sums)), min(sums))\n                \n    #return np.array([ [ np.dot(col0, col1) for col1 in img.T ] for img in xn1 ])","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:02:04.333042Z","iopub.execute_input":"2022-02-28T10:02:04.333628Z","iopub.status.idle":"2022-02-28T10:02:04.34375Z","shell.execute_reply.started":"2022-02-28T10:02:04.333572Z","shell.execute_reply":"2022-02-28T10:02:04.342524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The normalized sample from above. Still no needle visible","metadata":{}},{"cell_type":"markdown","source":"Now let's search the dataset for a copy of normalized column 128 in image 1 of our sample. I use col 128 because it's in the middle of the image. I search only a small subset of the full 60,000 samples dataset to keep running time short because I know from earlier runs where the match will be ;).","metadata":{}},{"cell_type":"markdown","source":"## Search-algorithm","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport csv\nbest_matches = []\nfor idy in tqdm(df_train_pos.id.iloc[10:30]):\n    css = []\n    x0 = load_example(idy)\n    xn0 = column_norm(x0)\n    for idx in tqdm(df_train.id.iloc[0:df_train.size]):\n        if idx == idy:\n            print(idx)\n        else:            \n            xn1 = column_norm(load_example(idx))\n            cs = find_similar_column_old(xn0[0,:,128], xn1)\n            csm = cs.max()\n            css.append((idx, csm, cs.argmax() % 273))\n    largest = max(css, key = lambda t: t[1])\n    best_matches.append({\"search\": idy, \"match\": largest})\nwith open('outputfile.csv', 'w') as csv_file:  \n    writer = csv.writer(csv_file)\n    for item in best_matches:        \n        for key, value in item.items():\n           writer.writerow([key, value])\nprint(best_matches)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:33:20.327436Z","iopub.execute_input":"2022-02-26T17:33:20.328241Z","iopub.status.idle":"2022-02-26T17:33:50.162428Z","shell.execute_reply.started":"2022-02-26T17:33:20.32819Z","shell.execute_reply":"2022-02-26T17:33:50.159316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"largest = max(css, key = lambda t: t[1])\ncss.remove(largest)\nlargest_2 = max(css, key = lambda t: t[1])\nprint(largest)\nprint(largest_2)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:33:50.163735Z","iopub.status.idle":"2022-02-26T17:33:50.164297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x1 = load_example(largest_2[0])\nxn1 = column_norm(x1)\n#result = find_similar_column(xn0[0,100:150], xn1[0,100:150])\n#print(result)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:33:50.165604Z","iopub.status.idle":"2022-02-26T17:33:50.166062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Found a perfect match: sample d87cb86179e9d02. Let's look at it. It is identical to 004933b94083be2 where they overlap It's only shifted by 128-68=60 frequency bins:\n\n#5: d87cb86179e9d02\n\n#12: b1f73e62e285d45","metadata":{}},{"cell_type":"code","source":"search_list = [{'search': '0024012d1431fbc', 'match': ('fa59fd3c6615824', 0.99999946, 14)}, \n{'search': '0028a35de92941d', 'match': ('e26ddbf40e0f281', 0.9393103, 26)}, \n{'search': '002efdabe4e3e45', 'match': ('e77d17e31e82c38', 0.9999997, 173)}, \n{'search': '0031e823c133be2', 'match': ('5bf8895f9bb6efb', 0.9079099, 128)}, \n{'search': '00412077d1aef6f', 'match': ('7fe84991f5f6808', 0.94292027, 252)}, \n{'search': '004933b94083be2', 'match': ('d87cb86179e9d02', 0.9999998, 68)}, \n{'search': '0055e9458a0f03a', 'match': ('390f9877282e72c', 0.48137662, 165)}, \n{'search': '00776881dd80050', 'match': ('9566e73eab8d403', 0.9999927, 241)}, \n{'search': '0080e5e1ef92b4c', 'match': ('4b3be228e8f66b0', 0.876866, 21)}, \n{'search': '008eb601300b642', 'match': ('008eb601300b642', 0.9999999, 128)}]","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:01:43.487468Z","iopub.execute_input":"2022-02-28T10:01:43.488087Z","iopub.status.idle":"2022-02-28T10:01:43.496807Z","shell.execute_reply.started":"2022-02-28T10:01:43.488048Z","shell.execute_reply":"2022-02-28T10:01:43.495964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for item in search_list:\n    print(item)\n    if (item['match'][1] > 0.95):\n        x0 = load_example(item['search']) \n        xn0 = column_norm(x0)\n        x1 = load_example(item['match'][0])\n        xn1 = column_norm(x1)\n        result = find_similar_column(xn0[0,:], xn1[0,:])\n        xn1_rolled = np.roll(xn1, result[0], axis=2)\n        show_example(xn0, 20) \n        show_example(xn1_rolled, 20) \n        show_example(xn1_rolled - xn0, 20)    ","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:02:07.437967Z","iopub.execute_input":"2022-02-28T10:02:07.438421Z","iopub.status.idle":"2022-02-28T10:02:12.405659Z","shell.execute_reply.started":"2022-02-28T10:02:07.438385Z","shell.execute_reply":"2022-02-28T10:02:12.403605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#xn0 = np.swapaxes(xn0,1,2)\n#xn1 = np.swapaxes(xn1,1,2)\nprint(xn0.shape)\nprint(xn1.shape)\nshow_example(xn0, 1)\nshow_example(xn1, 1)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:33:50.171323Z","iopub.status.idle":"2022-02-26T17:33:50.171777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = [100]\niteration = 0\nfor i in range(280):\n    test = xn0 - np.roll(xn1, i, axis=2)\n    cos = np.array([ [ np.dot(xn0[0,:,128], col1) for col1 in img.T ] for img in test ]).max()\n    results.append(cos)\n    if cos < results[iteration]:\n        iteration = i\nprint(iteration)\nprint(results[60])\nprint(results[127])","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:33:50.173029Z","iopub.status.idle":"2022-02-26T17:33:50.173517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Normalize it and subtract from the normalized sample xn0. Increasing the contrast a little, the needles are easily visible. The noise has been perfectly removed because of the leak. A 2-layer MLP could find these needles:","metadata":{}},{"cell_type":"code","source":"show_example(xn0)\nshow_example(np.roll(xn1, 60, axis=2))","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:33:50.174539Z","iopub.status.idle":"2022-02-26T17:33:50.174963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Increasing the contrast some more, numerical rounding errors become visible, except for where the artificial signals were inserted. Obviously using rectangles.","metadata":{}},{"cell_type":"code","source":"show_example(xn0 - np.roll(xn1, 128-68, axis=2), 40)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:33:50.175987Z","iopub.status.idle":"2022-02-26T17:33:50.176394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"That's all for now. Hope this clears up the magic a bit.\nAgain: congrats to Team Watercooled. Brilliant detective work!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}