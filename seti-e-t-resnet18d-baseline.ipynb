{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "I'd like to share an example for [small models](https://www.kaggle.com/c/seti-breakthrough-listen/discussion/242644)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model\n",
    "* backbone: resnet18d (use the pretrained model provided by [timm](https://github.com/rwightman/pytorch-image-models))\n",
    "* head classifier: one linear layer\n",
    "* num of input channels: **1**\n",
    "\n",
    "### data augmentation\n",
    "* implemented by [albumentations](https://albumentations.ai/docs/) **except for Mixup**\n",
    "* Train\n",
    "  * Resize\n",
    "  * HorizontalFlip\n",
    "  * VerticalFlip\n",
    "  * ShiftScaleRotate\n",
    "  * RandomResizedCrop\n",
    "  * Mixup(alpha=1.0)\n",
    "* Val, Test\n",
    "  * Resize\n",
    "\n",
    "### learning settings\n",
    "* CV Strategy: Stratified KFold (K=5)\n",
    "* max epochs: 18\n",
    "* data:\n",
    "  * input image size: 1x320x320\n",
    "  * batch size: 64\n",
    "* loss: [BCEWithLogitsLoss](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html#torch.nn.BCEWithLogitsLoss)\n",
    "* optimizer: [AdamW](https://pytorch.org/docs/stable/optim.html#torch.optim.AdamW)\n",
    "  * weight decay: 1.0e-04\n",
    "* learning rate scheduler: [OneCycleLR](https://pytorch.org/docs/stable/optim.html#torch.optim.lr_scheduler.OneCycleLR) \n",
    "  * epochs: 18\n",
    "  * max_lr: 1e-3\n",
    "  * pct_start: 0.111\n",
    "  * anneal_strategy: cos\n",
    "  * div_factor: 1.0e+2\n",
    "  * inal_div_factor: 1\n",
    "  \n",
    "### NOTE: I use only on-target ('A') observations\n",
    "import numpy as np\n",
    "```python\n",
    "img = np.load(path)[[0, 2, 4]]          # shape: (3, 273, 256)\n",
    "img = np.vstack(img)                    # shape: (819, 256)\n",
    "img = img.transpose(1, 0)               # shape: (256, 819)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prapere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-07-17T02:46:41.439742Z",
     "iopub.status.busy": "2021-07-17T02:46:41.43934Z",
     "iopub.status.idle": "2021-07-17T02:47:03.898351Z",
     "shell.execute_reply": "2021-07-17T02:47:03.897488Z",
     "shell.execute_reply.started": "2021-07-17T02:46:41.439661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in c:\\programdata\\anaconda3\\lib\\site-packages (0.4.12)\n",
      "Requirement already satisfied: torch>=1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from timm) (1.10.0+cu102)\n",
      "Requirement already satisfied: torchvision in c:\\programdata\\anaconda3\\lib\\site-packages (from timm) (0.11.1+cu102)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.4->timm) (4.0.0)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision->timm) (8.0.1)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision->timm) (1.19.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -raitlets (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -raitlets (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -raitlets (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -raitlets (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -raitlets (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in c:\\programdata\\anaconda3\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from albumentations) (1.19.2)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -raitlets (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -raitlets (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -raitlets (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -raitlets (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -raitlets (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: PyYAML in c:\\programdata\\anaconda3\\lib\\site-packages (from albumentations) (5.3.1)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from albumentations) (4.5.4.58)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from albumentations) (0.17.2)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from albumentations) (1.5.2)\n",
      "Requirement already satisfied: qudida>=0.0.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from albumentations) (0.0.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from qudida>=0.0.4->albumentations) (4.0.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from qudida>=0.0.4->albumentations) (0.23.2)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (3.3.2)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2.5)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (8.0.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2020.10.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2020.6.20)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (2.1.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#!{sys.executable} -m pip install pytorch_pfn_extras\n",
    "#!{sys.executable} -m pip install torch==1.10.0+cu102 torchvision==0.11.1+cu102 torchaudio===0.10.0+cu102 -f https://download.pytorch.org/whl/cu102/torch_stable.html\n",
    "!{sys.executable} -m pip install timm\n",
    "!{sys.executable} -m pip install albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-17T02:47:03.900548Z",
     "iopub.status.busy": "2021-07-17T02:47:03.900177Z",
     "iopub.status.idle": "2021-07-17T02:47:08.730574Z",
     "shell.execute_reply": "2021-07-17T02:47:08.729695Z",
     "shell.execute_reply.started": "2021-07-17T02:47:03.900506Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import yaml\n",
    "import random\n",
    "import shutil\n",
    "import typing as tp\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.cuda import amp\n",
    "\n",
    "import timm\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import pytorch_pfn_extras as ppe\n",
    "from pytorch_pfn_extras.config import Config\n",
    "from pytorch_pfn_extras.training import extensions as ppe_exts, triggers as ppe_triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T02:47:08.732801Z",
     "iopub.status.busy": "2021-07-17T02:47:08.732452Z",
     "iopub.status.idle": "2021-07-17T02:47:08.739525Z",
     "shell.execute_reply": "2021-07-17T02:47:08.737946Z",
     "shell.execute_reply.started": "2021-07-17T02:47:08.732761Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT = Path.cwd().parent\n",
    "INPUT = ROOT / \"SETI\"\n",
    "OUTPUT = ROOT / \"output\"\n",
    "DATA = INPUT / \"seti-breakthrough-listen\"\n",
    "TRAIN = DATA / \"train\"\n",
    "TEST = DATA / \"test\"\n",
    "\n",
    "TMP = ROOT / \"tmp\"\n",
    "TMP.mkdir(exist_ok=True)\n",
    "\n",
    "RANDAM_SEED = 1086\n",
    "CLASSES = [\"target\",]\n",
    "N_CLASSES = len(CLASSES)\n",
    "FOLDS = [0, 1, 2, 3, 4]\n",
    "N_FOLDS = len(FOLDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data, Split folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T02:47:08.741712Z",
     "iopub.status.busy": "2021-07-17T02:47:08.741284Z",
     "iopub.status.idle": "2021-07-17T02:47:08.842416Z",
     "shell.execute_reply": "2021-07-17T02:47:08.841645Z",
     "shell.execute_reply.started": "2021-07-17T02:47:08.741653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\source\\uni\\SETI\\seti-breakthrough-listen\n"
     ]
    }
   ],
   "source": [
    "print(DATA)\n",
    "train = pd.read_csv(DATA / \"train_labels.csv\")\n",
    "smpl_sub = pd.read_csv(DATA / \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T02:47:08.843891Z",
     "iopub.status.busy": "2021-07-17T02:47:08.843572Z",
     "iopub.status.idle": "2021-07-17T02:47:08.873474Z",
     "shell.execute_reply": "2021-07-17T02:47:08.872601Z",
     "shell.execute_reply.started": "2021-07-17T02:47:08.843854Z"
    }
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDAM_SEED)\n",
    "train[\"fold\"] = -1\n",
    "for fold_id, (_, val_idx) in enumerate(skf.split(train[\"id\"], train[\"target\"])):\n",
    "    train.loc[val_idx, \"fold\"] = fold_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T02:47:08.875118Z",
     "iopub.status.busy": "2021-07-17T02:47:08.874767Z",
     "iopub.status.idle": "2021-07-17T02:47:08.907557Z",
     "shell.execute_reply": "2021-07-17T02:47:08.906568Z",
     "shell.execute_reply.started": "2021-07-17T02:47:08.875082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      total   pos\nfold             \n0     12000  1200\n1     12000  1200\n2     12000  1200\n3     12000  1200\n4     12000  1200",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>total</th>\n      <th>pos</th>\n    </tr>\n    <tr>\n      <th>fold</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12000</td>\n      <td>1200</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>12000</td>\n      <td>1200</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12000</td>\n      <td>1200</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>12000</td>\n      <td>1200</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12000</td>\n      <td>1200</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(\"fold\").agg(total=(\"id\", len), pos=(\"target\", sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Model, Dataset, Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-07-17T02:47:08.909153Z",
     "iopub.status.busy": "2021-07-17T02:47:08.908803Z",
     "iopub.status.idle": "2021-07-17T02:47:08.919375Z",
     "shell.execute_reply": "2021-07-17T02:47:08.918377Z",
     "shell.execute_reply.started": "2021-07-17T02:47:08.909118Z"
    }
   },
   "outputs": [],
   "source": [
    "class BasicImageModel(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self, base_name: str, dims_head: tp.List[int],\n",
    "        pretrained=False, in_channels: int=3\n",
    "    ):\n",
    "        \"\"\"Initialize\"\"\"\n",
    "        self.base_name = base_name\n",
    "        super(BasicImageModel, self).__init__()\n",
    "        \n",
    "        # # prepare backbone\n",
    "        if hasattr(timm.models, base_name):\n",
    "            base_model = timm.create_model(\n",
    "                base_name, num_classes=0, pretrained=pretrained, in_chans=in_channels)\n",
    "            in_features = base_model.num_features\n",
    "            print(\"load imagenet pretrained:\", pretrained)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.backbone = base_model\n",
    "        print(f\"{base_name}: {in_features}\")\n",
    "        \n",
    "        # # prepare head clasifier\n",
    "        if dims_head[0] is None:\n",
    "            dims_head[0] = in_features\n",
    "\n",
    "        layers_list = []\n",
    "        for i in range(len(dims_head) - 2):\n",
    "            in_dim, out_dim = dims_head[i: i + 2]\n",
    "            layers_list.extend([\n",
    "                nn.Linear(in_dim, out_dim),\n",
    "                nn.ReLU(), nn.Dropout(0.5),])\n",
    "        layers_list.append(\n",
    "            nn.Linear(dims_head[-2], dims_head[-1]))\n",
    "        self.head_cls = nn.Sequential(*layers_list)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward\"\"\"\n",
    "        h = self.backbone(x)\n",
    "        h = self.head_cls(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T00:39:25.885782Z",
     "iopub.status.busy": "2021-06-03T00:39:25.885443Z",
     "iopub.status.idle": "2021-06-03T00:39:25.904695Z",
     "shell.execute_reply": "2021-06-03T00:39:25.903901Z",
     "shell.execute_reply.started": "2021-06-03T00:39:25.885753Z"
    }
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-07-17T02:47:08.923048Z",
     "iopub.status.busy": "2021-07-17T02:47:08.922628Z",
     "iopub.status.idle": "2021-07-17T02:47:08.937257Z",
     "shell.execute_reply": "2021-07-17T02:47:08.936082Z",
     "shell.execute_reply.started": "2021-07-17T02:47:08.922937Z"
    }
   },
   "outputs": [],
   "source": [
    "FilePath = tp.Union[str, Path]\n",
    "Label = tp.Union[int, float, np.ndarray]\n",
    "\n",
    "\n",
    "class SetiSimpleDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset using 6 channels by stacking them along time-axis\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    paths : tp.Sequence[FilePath]\n",
    "        Sequence of path to cadence snippet file\n",
    "    labels : tp.Sequence[Label]\n",
    "        Sequence of label for cadence snippet file\n",
    "    transform: albumentations.Compose\n",
    "        composed data augmentations for data\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        paths: tp.Sequence[FilePath],\n",
    "        labels: tp.Sequence[Label],\n",
    "        transform: A.Compose,\n",
    "    ):\n",
    "        \"\"\"Initialize\"\"\"\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return num of cadence snippets\"\"\"\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        \"\"\"Return transformed image and label for given index.\"\"\"\n",
    "        path, label = self.paths[index], self.labels[index]\n",
    "        img = self._read_cadence_array(path)\n",
    "        img = self.transform(image=img)[\"image\"]\n",
    "        return {\"image\": img, \"target\": label}\n",
    "\n",
    "    def _read_cadence_array(self, path: Path):\n",
    "        \"\"\"Read cadence file and reshape\"\"\"\n",
    "        img = np.load(path)  # shape: (6, 273, 256)\n",
    "        img = np.vstack(img)  # shape: (1638, 256)\n",
    "        img = img.transpose(1, 0)  # shape: (256, 1638)\n",
    "        img = img.astype(\"f\")[..., np.newaxis]  # shape: (256, 1638, 1)\n",
    "        return img\n",
    "\n",
    "    def lazy_init(self, paths=None, labels=None, transform=None):\n",
    "        \"\"\"Reset Members\"\"\"\n",
    "        if paths is not None:\n",
    "            self.paths = paths\n",
    "        if labels is not None:\n",
    "            self.labels = labels\n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "\n",
    "\n",
    "class SetiAObsDataset(SetiSimpleDataset):\n",
    "    \"\"\"Use only on-target observation\"\"\"\n",
    "\n",
    "    def _read_cadence_array(self, path: Path):\n",
    "        \"\"\"Read cadence file and reshape\"\"\"\n",
    "        img = np.load(path)[[0, 2, 4]]  # shape: (3, 273, 256)\n",
    "        img = np.vstack(img)  # shape: (819, 256)\n",
    "        img = img.transpose(1, 0)  # shape: (256, 819)\n",
    "        img = img.astype(\"f\")[..., np.newaxis]  # shape: (819, 256, 1)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-07-17T02:47:08.940003Z",
     "iopub.status.busy": "2021-07-17T02:47:08.939584Z",
     "iopub.status.idle": "2021-07-17T02:47:08.959973Z",
     "shell.execute_reply": "2021-07-17T02:47:08.959115Z",
     "shell.execute_reply.started": "2021-07-17T02:47:08.939962Z"
    }
   },
   "outputs": [],
   "source": [
    "Batch = tp.Union[tp.Tuple[torch.Tensor], tp.Dict[str, torch.Tensor]]\n",
    "ModelOut = tp.Union[tp.Tuple[torch.Tensor], tp.Dict[str, torch.Tensor], torch.Tensor]\n",
    "\n",
    "\n",
    "class ROCAUC(nn.Module):\n",
    "    \"\"\"ROC AUC score\"\"\"\n",
    "\n",
    "    def __init__(self, average=\"macro\") -> None:\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        self.average = average\n",
    "        super(ROCAUC, self).__init__()\n",
    "\n",
    "    def forward(self, y, t) -> float:\n",
    "        \"\"\"Forward.\"\"\"\n",
    "        if isinstance(y, torch.Tensor):\n",
    "            y = y.detach().cpu().numpy()\n",
    "        if isinstance(t, torch.Tensor):\n",
    "            t = t.detach().cpu().numpy()\n",
    "\n",
    "        return roc_auc_score(t, y, average=self.average)\n",
    "\n",
    "\n",
    "def micro_average(\n",
    "    metric_func: nn.Module,\n",
    "    report_name: str, prefix=\"val\",\n",
    "    pred_index: int=-1, label_index: int=-1,\n",
    "    pred_key: str=\"logit\", label_key: str=\"target\",\n",
    ") -> tp.Callable:\n",
    "    \"\"\"Return Metric Wrapper for Simple Mean Metric\"\"\"\n",
    "    metric_sum = [0.]\n",
    "    n_examples = [0]\n",
    "    \n",
    "    def wrapper(batch: Batch, model_output: ModelOut, is_last_batch: bool):\n",
    "        \"\"\"Wrapping metric function for evaluation\"\"\"\n",
    "        if isinstance(batch, tuple): \n",
    "            t = batch[label_index]\n",
    "        elif isinstance(batch, dict):\n",
    "            t = batch[label_key]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        if isinstance(model_output, tuple):\n",
    "            y = model_output[pred_index]\n",
    "        elif isinstance(model_output, dict):\n",
    "            y = model_output[pred_key]\n",
    "        else:\n",
    "            y = model_output\n",
    "\n",
    "        metric = metric_func(y, t).item()\n",
    "        metric_sum[0] += metric * y.shape[0]\n",
    "        n_examples[0] += y.shape[0]\n",
    "\n",
    "        if is_last_batch:\n",
    "            final_metric = metric_sum[0] / n_examples[0]\n",
    "            ppe.reporting.report({f\"{prefix}/{report_name}\": final_metric})\n",
    "            # # reset state\n",
    "            metric_sum[0] = 0.\n",
    "            n_examples[0] = 0\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def calc_across_all_batchs(\n",
    "    metric_func: nn.Module,\n",
    "    report_name: str, prefix=\"val\",\n",
    "    pred_index: int=-1, label_index: int=-1,\n",
    "    pred_key: str=\"logit\", label_key: str=\"target\",\n",
    ") -> tp.Callable:\n",
    "    \"\"\"\n",
    "    Return Metric Wrapper for Metrics caluculated on all data\n",
    "    \n",
    "    storing predictions and labels of evry batch, finally calculating metric on them.\n",
    "    \"\"\"\n",
    "    pred_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    def wrapper(batch: Batch, model_output: ModelOut, is_last_batch: bool):\n",
    "        \"\"\"Wrapping metric function for evaluation\"\"\"\n",
    "        if isinstance(batch, tuple):\n",
    "            t = batch[label_index]\n",
    "        elif isinstance(batch, dict):\n",
    "            t = batch[label_key]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        if isinstance(model_output, tuple):\n",
    "            y = model_output[pred_index]\n",
    "        elif isinstance(model_output, dict):\n",
    "            y = model_output[pred_key]\n",
    "        else:\n",
    "            y = model_output\n",
    "\n",
    "        pred_list.append(y.numpy())\n",
    "        label_list.append(t.numpy())\n",
    "\n",
    "        if is_last_batch:\n",
    "            pred = np.concatenate(pred_list, axis=0)\n",
    "            label = np.concatenate(label_list, axis=0)\n",
    "            final_metric = metric_func(pred, label)\n",
    "            ppe.reporting.report({f\"{prefix}/{report_name}\": final_metric})\n",
    "            # # reset state\n",
    "            pred_list[:] = []\n",
    "            label_list[:] = []\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## config_types for evaluating configuration\n",
    "\n",
    "I use [pytorch-pfn-extras](https://github.com/pfnet/pytorch-pfn-extras) for training NNs. This library has useful config systems but requires some preparation.\n",
    "\n",
    "For more details, see [docs](https://github.com/pfnet/pytorch-pfn-extras/blob/master/docs/config.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-07-17T02:47:08.961706Z",
     "iopub.status.busy": "2021-07-17T02:47:08.961242Z",
     "iopub.status.idle": "2021-07-17T02:47:08.97206Z",
     "shell.execute_reply": "2021-07-17T02:47:08.971024Z",
     "shell.execute_reply.started": "2021-07-17T02:47:08.961672Z"
    }
   },
   "outputs": [],
   "source": [
    "CONFIG_TYPES = {\n",
    "    # # utils\n",
    "    \"__len__\": lambda obj: len(obj),\n",
    "    \"method_call\": lambda obj, method: getattr(obj, method)(),\n",
    "\n",
    "    # # Dataset, DataLoader\n",
    "    \"SetiSimpleDataset\": SetiSimpleDataset,\n",
    "    \"SetiAObsDataset\": SetiAObsDataset,\n",
    "    \"DataLoader\": torch.utils.data.DataLoader,\n",
    "\n",
    "    # # Data Augmentation\n",
    "    \"Compose\": A.Compose, \"OneOf\": A.OneOf,\n",
    "    \"Resize\": A.Resize,\n",
    "    \"HorizontalFlip\": A.HorizontalFlip, \"VerticalFlip\": A.VerticalFlip,\n",
    "    \"ShiftScaleRotate\": A.ShiftScaleRotate,\n",
    "    \"RandomResizedCrop\": A.RandomResizedCrop,\n",
    "    \"Cutout\": A.Cutout,\n",
    "    \"ToTensorV2\": ToTensorV2,\n",
    "\n",
    "    # # Model\n",
    "    \"BasicImageModel\": BasicImageModel,\n",
    "\n",
    "    # # Optimizer\n",
    "    \"AdamW\": optim.AdamW,\n",
    "\n",
    "    # # Scheduler\n",
    "    \"OneCycleLR\": lr_scheduler.OneCycleLR,\n",
    "\n",
    "    # # Loss,Metric\n",
    "    \"BCEWithLogitsLoss\": nn.BCEWithLogitsLoss,\n",
    "    \"ROCAUC\": ROCAUC,\n",
    "\n",
    "    # # Metric Wrapper\n",
    "    \"micro_average\": micro_average,\n",
    "    \"calc_across_all_batchs\": calc_across_all_batchs,\n",
    "\n",
    "    # # PPE Extensions\n",
    "    \"ExtensionsManager\": ppe.training.ExtensionsManager,\n",
    "\n",
    "    \"observe_lr\": ppe_exts.observe_lr,\n",
    "    \"LogReport\": ppe_exts.LogReport,\n",
    "    \"PlotReport\": ppe_exts.PlotReport,\n",
    "    \"PrintReport\": ppe_exts.PrintReport,\n",
    "    \"PrintReportNotebook\": ppe_exts.PrintReportNotebook,\n",
    "    \"ProgressBar\": ppe_exts.ProgressBar,\n",
    "    \"ProgressBarNotebook\": ppe_exts.ProgressBarNotebook,\n",
    "    \"snapshot\": ppe_exts.snapshot,\n",
    "    \"LRScheduler\": ppe_exts.LRScheduler, \n",
    "\n",
    "    \"MinValueTrigger\": ppe_triggers.MinValueTrigger,\n",
    "    \"MaxValueTrigger\": ppe_triggers.MaxValueTrigger,\n",
    "    \"EarlyStoppingTrigger\": ppe_triggers.EarlyStoppingTrigger,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## configration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T02:47:08.973809Z",
     "iopub.status.busy": "2021-07-17T02:47:08.973392Z",
     "iopub.status.idle": "2021-07-17T02:47:09.006427Z",
     "shell.execute_reply": "2021-07-17T02:47:09.005559Z",
     "shell.execute_reply.started": "2021-07-17T02:47:08.973772Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_eval_cfg = yaml.safe_load(\n",
    "\"\"\"\n",
    "globals:\n",
    "  seed: 1086\n",
    "  val_fold: null  # indicate when training\n",
    "  output_path: null # indicate when training\n",
    "  device: cuda\n",
    "  enable_amp: False\n",
    "  max_epoch: 18\n",
    "\n",
    "model:\n",
    "  type: BasicImageModel\n",
    "  dims_head: [null, 1]\n",
    "  base_name: resnet18d\n",
    "  pretrained: True\n",
    "  in_channels: 1\n",
    "\n",
    "dataset:\n",
    "  height: 320\n",
    "  width: 320\n",
    "  mixup: {enabled: True, alpha: 1.0}\n",
    "  train:\n",
    "    type: SetiAObsDataset\n",
    "    paths: null  # set by lazy_init\n",
    "    labels: null  # set by lazy_init\n",
    "    transform:\n",
    "      type: Compose\n",
    "      transforms:\n",
    "        - {type: Resize, p: 1.0, height: \"@/dataset/height\", width: \"@/dataset/width\"}\n",
    "        - {type: HorizontalFlip, p: 0.5}\n",
    "        - {type: VerticalFlip, p: 0.5}\n",
    "        - {type: ShiftScaleRotate, p: 0.5, shift_limit: 0.2, scale_limit: 0.2,\n",
    "            rotate_limit: 20, border_mode: 0, value: 0, mask_value: 0}\n",
    "        - {type: RandomResizedCrop, p: 1.0,\n",
    "            scale: [0.9, 1.0], height: \"@/dataset/height\", width: \"@/dataset/width\"}\n",
    "        - {type: ToTensorV2, always_apply: True}\n",
    "  val:\n",
    "    type: SetiAObsDataset\n",
    "    paths: null  # set by lazy_init\n",
    "    labels: null  # set by lazy_init\n",
    "    transform:\n",
    "      type: Compose\n",
    "      transforms:\n",
    "        - {type: Resize, p: 1.0, height: \"@/dataset/height\", width: \"@/dataset/width\"}\n",
    "        - {type: ToTensorV2, always_apply: True}  \n",
    "  test:\n",
    "    type: SetiAObsDataset\n",
    "    paths: null  # set by lazy_init\n",
    "    labels: null  # set by lazy_init\n",
    "    transform: \"@/dataset/val/transform\"\n",
    "\n",
    "loader:\n",
    "  train: {type: DataLoader, dataset: \"@/dataset/train\",\n",
    "    batch_size: 64, num_workers: 4, shuffle: True, pin_memory: True, drop_last: True}\n",
    "  val: {type: DataLoader, dataset: \"@/dataset/val\",\n",
    "    batch_size: 128, num_workers: 4, shuffle: False, pin_memory: True, drop_last: False}\n",
    "  test: {type: DataLoader, dataset: \"@/dataset/test\",\n",
    "    batch_size: 128, num_workers: 4, shuffle: False, pin_memory: True, drop_last: False}\n",
    "\n",
    "optimizer:\n",
    "  type: AdamW\n",
    "  params: {type: method_call, obj: \"@/model\", method: parameters}\n",
    "  lr: 1.0e-05\n",
    "  weight_decay: 1.0e-04\n",
    "\n",
    "scheduler:\n",
    "  type: OneCycleLR\n",
    "  optimizer: \"@/optimizer\"\n",
    "  epochs: \"@/globals/max_epoch\"\n",
    "  steps_per_epoch: {type: __len__, obj: \"@/loader/train\"}\n",
    "  max_lr: 1.0e-3\n",
    "  pct_start: 0.111\n",
    "  anneal_strategy: cos\n",
    "  div_factor: 1.0e+2\n",
    "  final_div_factor: 1\n",
    "\n",
    "loss: {type: BCEWithLogitsLoss}\n",
    "\n",
    "eval:\n",
    "  - type: micro_average\n",
    "    metric_func: {type: BCEWithLogitsLoss}\n",
    "    report_name: loss\n",
    "  - type: calc_across_all_batchs\n",
    "    metric_func: {type: ROCAUC}\n",
    "    report_name: metric\n",
    "\n",
    "manager:\n",
    "  type: ExtensionsManager\n",
    "  models: \"@/model\"\n",
    "  optimizers: \"@/optimizer\"\n",
    "  max_epochs: \"@/globals/max_epoch\"\n",
    "  iters_per_epoch: {type: __len__, obj: \"@/loader/train\"}\n",
    "  out_dir: \"@/globals/output_path\"\n",
    "  # stop_trgiger: {type: EarlyStoppingTrigger,\n",
    "  #   monitor: val/metric, mode: max, patience: 5, verbose: True,\n",
    "  #   check_trigger: [1, epoch], max_trigger: [\"@/globals/max_epoch\", epoch]}\n",
    "\n",
    "extensions:\n",
    "  # # log\n",
    "  - {type: observe_lr, optimizer: \"@/optimizer\"}\n",
    "  - {type: LogReport}\n",
    "  - {type: PlotReport, y_keys: lr, x_key: epoch, filename: lr.png}\n",
    "  - {type: PlotReport, y_keys: [train/loss, val/loss], x_key: epoch, filename: loss.png}\n",
    "  - {type: PlotReport, y_keys: val/metric, x_key: epoch, filename: metric.png}\n",
    "  - {type: PrintReport, entries: [\n",
    "      epoch, iteration, lr, train/loss, val/loss, val/metric, elapsed_time]}\n",
    "  - {type: ProgressBarNotebook, update_interval: 20}\n",
    "  # snapshot\n",
    "  - extension: {type: snapshot, target: \"@/model\", filename: \"snapshot_by_metric_epoch_{.epoch}.pth\"}\n",
    "    trigger: {type: MaxValueTrigger, key: \"val/metric\", trigger: [1, epoch]}\n",
    "  # # lr scheduler\n",
    "  - {type: LRScheduler, scheduler: \"@/scheduler\", trigger: [1,  iteration]}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-07-17T02:47:09.008239Z",
     "iopub.status.busy": "2021-07-17T02:47:09.007834Z",
     "iopub.status.idle": "2021-07-17T02:47:09.017308Z",
     "shell.execute_reply": "2021-07-17T02:47:09.016157Z",
     "shell.execute_reply.started": "2021-07-17T02:47:09.008203Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_random_seed(seed: int = 42, deterministic: bool = False):\n",
    "    \"\"\"Set seeds\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = deterministic  # type: ignore\n",
    "\n",
    "\n",
    "def to_device(\n",
    "    tensors: tp.Union[tp.Tuple[torch.Tensor], tp.Dict[str, torch.Tensor]],\n",
    "    device: torch.device, *args, **kwargs\n",
    "):\n",
    "    if isinstance(tensors, tuple):\n",
    "        return (t.to(device, *args, **kwargs) for t in tensors)\n",
    "    elif isinstance(tensors, dict):\n",
    "        return {\n",
    "            k: t.to(device, *args, **kwargs) for k, t in tensors.items()}\n",
    "    else:\n",
    "        return tensors.to(device, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-07-17T02:47:09.019164Z",
     "iopub.status.busy": "2021-07-17T02:47:09.018744Z",
     "iopub.status.idle": "2021-07-17T02:47:09.033723Z",
     "shell.execute_reply": "2021-07-17T02:47:09.032892Z",
     "shell.execute_reply.started": "2021-07-17T02:47:09.019127Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_path_label(cfg: Config, train_all: pd.DataFrame):\n",
    "    \"\"\"Get file path and target info.\"\"\"\n",
    "    use_fold = cfg[\"/globals/val_fold\"]\n",
    "\n",
    "    train_df = train_all[train_all[\"fold\"] != use_fold]\n",
    "    val_df = train_all[train_all[\"fold\"] == use_fold]\n",
    "    \n",
    "    train_path_label = {\n",
    "        \"paths\": [TRAIN / f\"{img_id[0]}/{img_id}.npy\" for img_id in train_df[\"id\"].values],\n",
    "        \"labels\": train_df[CLASSES].values.astype(\"f\")}\n",
    "    val_path_label = {\n",
    "        \"paths\": [TRAIN / f\"{img_id[0]}/{img_id}.npy\" for img_id in val_df[\"id\"].values],\n",
    "        \"labels\": val_df[CLASSES].values.astype(\"f\")\n",
    "    }\n",
    "    return train_path_label, val_path_label\n",
    "\n",
    "\n",
    "def get_eval_func(cfg, model, device):\n",
    "    \n",
    "    def eval_func(**batch):\n",
    "        \"\"\"Run evaliation for val or test. This function is applied to each batch.\"\"\"\n",
    "        batch = to_device(batch, device)\n",
    "        x = batch[\"image\"]\n",
    "        with amp.autocast(cfg[\"/globals/enable_amp\"]): \n",
    "            y = model(x)\n",
    "        return y.detach().cpu().to(torch.float32)  # input of metrics\n",
    "\n",
    "    return eval_func\n",
    "\n",
    "\n",
    "def mixup_data(use_mixup, x, t, alpha=1.0, use_cuda=True):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if not use_mixup:\n",
    "        return x, t, None, None\n",
    "    \n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    t_a, t_b = t, t[index]\n",
    "    return mixed_x, t_a, t_b, lam\n",
    "\n",
    "\n",
    "def get_criterion(use_mixup, loss_func):\n",
    "\n",
    "    def mixup_criterion(pred, t_a, t_b, lam):\n",
    "        return lam * loss_func(pred, t_a) + (1 - lam) * loss_func(pred, t_b)\n",
    "\n",
    "    def single_criterion(pred, t_a, t_b, lam):\n",
    "        return loss_func(pred, t_a)\n",
    "    \n",
    "    if use_mixup:\n",
    "        return mixup_criterion\n",
    "    else:\n",
    "        return single_criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T02:47:09.035452Z",
     "iopub.status.busy": "2021-07-17T02:47:09.034926Z",
     "iopub.status.idle": "2021-07-17T02:47:09.050335Z",
     "shell.execute_reply": "2021-07-17T02:47:09.049626Z",
     "shell.execute_reply.started": "2021-07-17T02:47:09.035282Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_fold(cfg, train_all):\n",
    "    \"\"\"Main\"\"\"\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    set_random_seed(cfg[\"/globals/seed\"], deterministic=True)\n",
    "    device = torch.device(cfg[\"/globals/device\"])\n",
    "    \n",
    "    train_path_label, val_path_label = get_path_label(cfg, train_all)\n",
    "    print(\"train: {}, val: {}\".format(len(train_path_label[\"paths\"]), len(val_path_label[\"paths\"])))\n",
    "   \n",
    "    cfg[\"/dataset/train\"].lazy_init(**train_path_label)\n",
    "    cfg[\"/dataset/val\"].lazy_init(**val_path_label)\n",
    "    train_loader = cfg[\"/loader/train\"]\n",
    "    val_loader = cfg[\"/loader/val\"]\n",
    "\n",
    "    model = cfg[\"/model\"]\n",
    "    model.to(device)\n",
    "    optimizer = cfg[\"/optimizer\"]\n",
    "    loss_func = cfg[\"/loss\"]\n",
    "    loss_func.to(device)\n",
    "    \n",
    "    manager = cfg[\"/manager\"]\n",
    "    for ext in cfg[\"/extensions\"]:\n",
    "        if isinstance(ext, dict):\n",
    "            manager.extend(**ext)\n",
    "        else:\n",
    "            manager.extend(ext)\n",
    "\n",
    "    evaluator = ppe_exts.Evaluator(\n",
    "        val_loader, model, eval_func=get_eval_func(cfg, model, device),\n",
    "        metrics=cfg[\"/eval\"], progress_bar=False)\n",
    "    manager.extend(evaluator, trigger=(1, \"epoch\"))\n",
    "\n",
    "    use_amp = cfg[\"/globals/enable_amp\"]\n",
    "    scaler = amp.GradScaler(enabled=use_amp)\n",
    "    use_mixup = cfg[\"/dataset/mixup/enabled\"]\n",
    "    mixup_alpha = cfg[\"/dataset/mixup/alpha\"]\n",
    "    \n",
    "    while not manager.stop_trigger:\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            with manager.run_iteration():\n",
    "                batch = to_device(batch, device)\n",
    "                x, t = batch[\"image\"], batch[\"target\"]\n",
    "                # # for mixup\n",
    "                mixed_x, t_a, t_b, lam = mixup_data(use_mixup, x, t, mixup_alpha)\n",
    "                criterion = get_criterion(use_mixup, loss_func)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                with amp.autocast(use_amp):\n",
    "                    y = model(mixed_x)\n",
    "                    loss = criterion(y, t_a, t_b, lam)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                \n",
    "                ppe.reporting.report({'train/loss': loss.item()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T02:47:09.051998Z",
     "iopub.status.busy": "2021-07-17T02:47:09.051654Z",
     "iopub.status.idle": "2021-07-17T02:47:09.060983Z",
     "shell.execute_reply": "2021-07-17T02:47:09.060198Z",
     "shell.execute_reply.started": "2021-07-17T02:47:09.051961Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_eval_cfg_list = []\n",
    "for fold_id in FOLDS:\n",
    "    tmp_cfg = copy.deepcopy(pre_eval_cfg)\n",
    "    tmp_cfg[\"globals\"][\"val_fold\"] = fold_id\n",
    "    tmp_cfg[\"globals\"][\"output_path\"] = str(TMP / f\"fold{fold_id}\")\n",
    "    pre_eval_cfg_list.append(tmp_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[{'globals': {'seed': 1086, 'val_fold': 0, 'output_path': 'C:\\\\source\\\\uni\\\\tmp\\\\fold0', 'device': 'cuda', 'enable_amp': False, 'max_epoch': 18}, 'model': {'type': 'BasicImageModel', 'dims_head': [None, 1], 'base_name': 'resnet18d', 'pretrained': True, 'in_channels': 1}, 'dataset': {'height': 320, 'width': 320, 'mixup': {'enabled': True, 'alpha': 1.0}, 'train': {'type': 'SetiAObsDataset', 'paths': None, 'labels': None, 'transform': {'type': 'Compose', 'transforms': [{'type': 'Resize', 'p': 1.0, 'height': '@/dataset/height', 'width': '@/dataset/width'}, {'type': 'HorizontalFlip', 'p': 0.5}, {'type': 'VerticalFlip', 'p': 0.5}, {'type': 'ShiftScaleRotate', 'p': 0.5, 'shift_limit': 0.2, 'scale_limit': 0.2, 'rotate_limit': 20, 'border_mode': 0, 'value': 0, 'mask_value': 0}, {'type': 'RandomResizedCrop', 'p': 1.0, 'scale': [0.9, 1.0], 'height': '@/dataset/height', 'width': '@/dataset/width'}, {'type': 'ToTensorV2', 'always_apply': True}]}}, 'val': {'type': 'SetiAObsDataset', 'paths': None, 'labels': None, 'transform': {'type': 'Compose', 'transforms': [{'type': 'Resize', 'p': 1.0, 'height': '@/dataset/height', 'width': '@/dataset/width'}, {'type': 'ToTensorV2', 'always_apply': True}]}}, 'test': {'type': 'SetiAObsDataset', 'paths': None, 'labels': None, 'transform': '@/dataset/val/transform'}}, 'loader': {'train': {'type': 'DataLoader', 'dataset': '@/dataset/train', 'batch_size': 64, 'num_workers': 4, 'shuffle': True, 'pin_memory': True, 'drop_last': True}, 'val': {'type': 'DataLoader', 'dataset': '@/dataset/val', 'batch_size': 128, 'num_workers': 4, 'shuffle': False, 'pin_memory': True, 'drop_last': False}, 'test': {'type': 'DataLoader', 'dataset': '@/dataset/test', 'batch_size': 128, 'num_workers': 4, 'shuffle': False, 'pin_memory': True, 'drop_last': False}}, 'optimizer': {'type': 'AdamW', 'params': {'type': 'method_call', 'obj': '@/model', 'method': 'parameters'}, 'lr': 1e-05, 'weight_decay': 0.0001}, 'scheduler': {'type': 'OneCycleLR', 'optimizer': '@/optimizer', 'epochs': '@/globals/max_epoch', 'steps_per_epoch': {'type': '__len__', 'obj': '@/loader/train'}, 'max_lr': 0.001, 'pct_start': 0.111, 'anneal_strategy': 'cos', 'div_factor': 100.0, 'final_div_factor': 1}, 'loss': {'type': 'BCEWithLogitsLoss'}, 'eval': [{'type': 'micro_average', 'metric_func': {'type': 'BCEWithLogitsLoss'}, 'report_name': 'loss'}, {'type': 'calc_across_all_batchs', 'metric_func': {'type': 'ROCAUC'}, 'report_name': 'metric'}], 'manager': {'type': 'ExtensionsManager', 'models': '@/model', 'optimizers': '@/optimizer', 'max_epochs': '@/globals/max_epoch', 'iters_per_epoch': {'type': '__len__', 'obj': '@/loader/train'}, 'out_dir': '@/globals/output_path'}, 'extensions': [{'type': 'observe_lr', 'optimizer': '@/optimizer'}, {'type': 'LogReport'}, {'type': 'PlotReport', 'y_keys': 'lr', 'x_key': 'epoch', 'filename': 'lr.png'}, {'type': 'PlotReport', 'y_keys': ['train/loss', 'val/loss'], 'x_key': 'epoch', 'filename': 'loss.png'}, {'type': 'PlotReport', 'y_keys': 'val/metric', 'x_key': 'epoch', 'filename': 'metric.png'}, {'type': 'PrintReport', 'entries': ['epoch', 'iteration', 'lr', 'train/loss', 'val/loss', 'val/metric', 'elapsed_time']}, {'type': 'ProgressBarNotebook', 'update_interval': 20}, {'extension': {'type': 'snapshot', 'target': '@/model', 'filename': 'snapshot_by_metric_epoch_{.epoch}.pth'}, 'trigger': {'type': 'MaxValueTrigger', 'key': 'val/metric', 'trigger': [1, 'epoch']}}, {'type': 'LRScheduler', 'scheduler': '@/scheduler', 'trigger': [1, 'iteration']}]}]\n",
      "                    id  target  fold\n",
      "0      0000799a2b2c42d       0     4\n",
      "1      00042890562ff68       0     2\n",
      "2      0005364cdcb8e5b       0     2\n",
      "3      0007a5a46901c56       0     4\n",
      "4      0009283e145448e       0     1\n",
      "...                ...     ...   ...\n",
      "59995  fff8217fe05aba3       0     4\n",
      "59996  fffa939e610ed70       0     1\n",
      "59997  fffbb1c9c3d6c31       1     2\n",
      "59998  fffc9a763d23647       0     4\n",
      "59999  ffff0a799efa529       0     4\n",
      "\n",
      "[60000 rows x 3 columns]\n",
      "<pytorch_pfn_extras.config.Config object at 0x00000208E04320A0>\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(pre_eval_cfg_list)\n",
    "print(train)\n",
    "print(Config(pre_eval_cfg, types=CONFIG_TYPES))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T02:47:09.063857Z",
     "iopub.status.busy": "2021-07-17T02:47:09.063183Z",
     "iopub.status.idle": "2021-07-17T02:53:48.164174Z",
     "shell.execute_reply": "2021-07-17T02:53:48.158346Z",
     "shell.execute_reply.started": "2021-07-17T02:47:09.06382Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[fold 0]\n",
      "train: 48000, val: 12000\n",
      "load imagenet pretrained: True\n",
      "resnet18d: 512\n"
     ]
    },
    {
     "data": {
      "text/plain": "VBox(children=(HBox(children=(FloatProgress(value=0.0, bar_style='info', description='total', max=1.0), HTML(vâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4258e1602a6843d9922b42de99a82182"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for pre_eval_cfg in pre_eval_cfg_list:\n",
    "    cfg = Config(pre_eval_cfg, types=CONFIG_TYPES)\n",
    "    print(f\"\\n[fold {cfg['/globals/val_fold']}]\")\n",
    "    train_one_fold(cfg, train)\n",
    "    del cfg\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-07-17T02:53:48.167388Z",
     "iopub.status.idle": "2021-07-17T02:53:48.167798Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-18-a6875f96c1be>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mpre_eval_cfg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfold_id\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpre_eval_cfg_list\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mFOLDS\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m     \u001B[0mexp_dir_path\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTMP\u001B[0m \u001B[1;33m/\u001B[0m \u001B[1;34mf\"fold{fold_id}\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m     \u001B[0mlog\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_json\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mexp_dir_path\u001B[0m \u001B[1;33m/\u001B[0m \u001B[1;34m\"log\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m     \u001B[0mbest_log\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlog\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mlog\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"val/metric\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0midxmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[0mbest_epoch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbest_log\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mepoch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    197\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    198\u001B[0m                     \u001B[0mkwargs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mnew_arg_name\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnew_arg_value\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 199\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    200\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    201\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mcast\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mF\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    294\u001B[0m                 )\n\u001B[0;32m    295\u001B[0m                 \u001B[0mwarnings\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwarn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mFutureWarning\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstacklevel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 296\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    297\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    298\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001B[0m in \u001B[0;36mread_json\u001B[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression, nrows)\u001B[0m\n\u001B[0;32m    616\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mjson_reader\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    617\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 618\u001B[1;33m     \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mjson_reader\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    619\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mshould_close\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    620\u001B[0m         \u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001B[0m in \u001B[0;36mread\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    753\u001B[0m                 \u001B[0mobj\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_object_parser\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_combine_lines\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    754\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 755\u001B[1;33m             \u001B[0mobj\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_object_parser\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    756\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    757\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mobj\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001B[0m in \u001B[0;36m_get_object_parser\u001B[1;34m(self, json)\u001B[0m\n\u001B[0;32m    775\u001B[0m         \u001B[0mobj\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    776\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mtyp\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"frame\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 777\u001B[1;33m             \u001B[0mobj\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mFrameParser\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mjson\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    778\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    779\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mtyp\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"series\"\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mobj\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001B[0m in \u001B[0;36mparse\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    884\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    885\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 886\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_parse_no_numpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    887\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    888\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mobj\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001B[0m in \u001B[0;36m_parse_no_numpy\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1117\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0morient\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"columns\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1118\u001B[0m             self.obj = DataFrame(\n\u001B[1;32m-> 1119\u001B[1;33m                 \u001B[0mloads\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mjson\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprecise_float\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprecise_float\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1120\u001B[0m             )\n\u001B[0;32m   1121\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0morient\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"split\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "best_log_list = []\n",
    "for pre_eval_cfg, fold_id in zip(pre_eval_cfg_list, FOLDS):\n",
    "    exp_dir_path = TMP / f\"fold{fold_id}\"\n",
    "    log = pd.read_json(exp_dir_path / \"log\")\n",
    "    best_log = log.iloc[[log[\"val/metric\"].idxmax()],]\n",
    "    best_epoch = best_log.epoch.values[0]\n",
    "    best_log_list.append(best_log)\n",
    "    \n",
    "    best_model_path = exp_dir_path / f\"snapshot_by_metric_epoch_{best_epoch}.pth\"\n",
    "    copy_to = f\"./best_metric_model_fold{fold_id}.pth\"\n",
    "    shutil.copy(best_model_path, copy_to)\n",
    "    \n",
    "    for p in exp_dir_path.glob(\"*.pth\"):\n",
    "        p.unlink()\n",
    "    \n",
    "    shutil.copytree(exp_dir_path, f\"./fold{fold_id}\")\n",
    "    \n",
    "    with open(f\"./fold{fold_id}/config.yml\", \"w\") as fw:\n",
    "        yaml.dump(pre_eval_cfg, fw)\n",
    "    \n",
    "pd.concat(best_log_list, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference OOF & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.status.busy": "2021-07-17T02:53:48.169158Z",
     "iopub.status.idle": "2021-07-17T02:53:48.169723Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_inference_loop(cfg, model, loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader):\n",
    "            x = to_device(batch[\"image\"], device)\n",
    "            y = model(x)\n",
    "            pred_list.append(y.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    pred_arr = np.concatenate(pred_list)\n",
    "    del pred_list\n",
    "    return pred_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-07-17T02:53:48.170938Z",
     "iopub.status.idle": "2021-07-17T02:53:48.171542Z"
    }
   },
   "outputs": [],
   "source": [
    "label_arr = train[CLASSES].values\n",
    "oof_pred_arr = np.zeros((len(train), N_CLASSES))\n",
    "score_list = []\n",
    "test_pred_arr = np.zeros((N_FOLDS, len(smpl_sub), N_CLASSES))\n",
    "test_path_label = {\n",
    "    \"paths\": [DATA / f\"test/{img_id[0]}/{img_id}.npy\" for img_id in smpl_sub[\"id\"].values],\n",
    "    \"labels\": smpl_sub[CLASSES].values.astype(\"f\")\n",
    "}\n",
    "\n",
    "for fold_id in range(N_FOLDS):\n",
    "    print(f\"\\n[fold {fold_id}]\")\n",
    "    tmp_dir = Path(f\"./fold{fold_id}\")\n",
    "    with open(tmp_dir / \"config.yml\", \"r\") as fr:\n",
    "        cfg = Config(yaml.safe_load(fr), types=CONFIG_TYPES)\n",
    "    device = torch.device(cfg[\"/globals/device\"])\n",
    "    val_idx = train.query(\"fold == @fold_id\").index.values\n",
    "\n",
    "    # # get_dataloader\n",
    "    _, val_path_label = get_path_label(cfg, train)\n",
    "    cfg[\"/dataset/val\"].lazy_init(**val_path_label)\n",
    "    cfg[\"/dataset/test\"].lazy_init(**test_path_label)\n",
    "    val_loader = cfg[\"/loader/val\"]\n",
    "    test_loader = cfg[\"/loader/test\"]\n",
    "    \n",
    "    # # get model\n",
    "    model_path = f\"./best_metric_model_fold{fold_id}.pth\"\n",
    "    model = cfg[\"/model\"]\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    \n",
    "    # # inference\n",
    "    val_pred = run_inference_loop(cfg, model, val_loader, device)\n",
    "    val_score = roc_auc_score(label_arr[val_idx], val_pred)\n",
    "    oof_pred_arr[val_idx] = val_pred\n",
    "    score_list.append([fold_id, val_score])\n",
    "    \n",
    "    test_pred_arr[fold_id] = run_inference_loop(cfg, model, test_loader, device)\n",
    "    \n",
    "    del cfg, val_idx, val_path_label\n",
    "    del model, val_loader, test_loader\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"val score: {val_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-07-17T02:53:48.172705Z",
     "iopub.status.idle": "2021-07-17T02:53:48.173321Z"
    }
   },
   "outputs": [],
   "source": [
    "oof_score = roc_auc_score(label_arr, oof_pred_arr)\n",
    "score_list.append([\"oof\", oof_score])\n",
    "pd.DataFrame(score_list, columns=[\"fold\", \"metric\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-07-17T02:53:48.174413Z",
     "iopub.status.idle": "2021-07-17T02:53:48.175128Z"
    }
   },
   "outputs": [],
   "source": [
    "oof_df = train.copy()\n",
    "oof_df[CLASSES] = oof_pred_arr\n",
    "oof_df.to_csv(\"./oof_prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-07-17T02:53:48.176194Z",
     "iopub.status.idle": "2021-07-17T02:53:48.176783Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_df = smpl_sub.copy()\n",
    "sub_df[CLASSES] = test_pred_arr.mean(axis=0)\n",
    "sub_df.to_csv(\"./submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-07-17T02:53:48.177983Z",
     "iopub.status.idle": "2021-07-17T02:53:48.178596Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EOF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}